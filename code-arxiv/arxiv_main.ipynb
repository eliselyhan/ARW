{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.modules.pop('generate_syn_data', None)\n",
    "from generate_syn_data import *\n",
    "\n",
    "sys.modules.pop('ARW', None)\n",
    "from ARW import *\n",
    "\n",
    "sys.modules.pop('split', None)\n",
    "from split import *\n",
    "\n",
    "sys.modules.pop('algo_syn', None)\n",
    "from algo_syn import *\n",
    "\n",
    "sys.modules.pop('arxiv_read', None)\n",
    "from arxiv_read import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read data\n",
    "# reader = readArxiv()\n",
    "# num_periods = 200\n",
    "# end = '20231231'\n",
    "# window_width = 7\n",
    "# category_list = ['cs.LG']\n",
    "\n",
    "# abs_list, B_arr = reader.get_abstracts(num_periods = num_periods, end=end, window_width=window_width,category_list=category_list)\n",
    "\n",
    "# ngrams = [('deep',), ('neural',), ('dnn',), ('dnns',)]\n",
    "# X = reader.get_X_data(abs_list = abs_list, ngrams = ngrams, task='count')\n",
    "\n",
    "# #save X and B_arr\n",
    "# with open('./pickle/X_DL.pkl', 'wb') as f:\n",
    "#     pickle.dump(X, f)\n",
    "# with open('./pickle/B_arr_DL.pkl', 'wb') as f:\n",
    "#     pickle.dump(B_arr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_periods = 200\n",
    "end = '20231231'\n",
    "window_width = 7\n",
    "category_list = ['cs.LG']\n",
    "\n",
    "with open('./pickle/X_DL.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('./pickle/B_arr_DL.pkl', 'rb') as f:\n",
    "    B_arr = pickle.load(f)\n",
    "    \n",
    "\n",
    "np.random.seed(20)\n",
    "B_arr = B_arr.astype(int)\n",
    "\n",
    "# clip the validation B_arr to have at most (N) per period\n",
    "B_arr_val = np.floor(B_arr).astype(int)\n",
    "B_arr_val = np.clip(B_arr_val, 0, 5)\n",
    "print('maximum # B_val per period:', max(B_arr_val), '\\nminimum # B_val per period:', min(B_arr_val), '\\nmean # B_val per period:', np.mean(B_arr_val))\n",
    "\n",
    "B_arr_train = 3 * B_arr_val\n",
    "B_arr_test = B_arr - B_arr_train - B_arr_val\n",
    "print('\\nmaximum # B_test per period:', max(B_arr_test), '\\nminimum # B_test per period:', min(B_arr_test), '\\nmean # B_test per period:', np.mean(B_arr_test))\n",
    "\n",
    "# compute the start and end indices for each period\n",
    "B_arr_train_starts = np.cumsum(B_arr_train) - B_arr_train\n",
    "B_arr_train_ends = np.cumsum(B_arr_train) - 1\n",
    "B_arr_val_starts = np.cumsum(B_arr_val) - B_arr_val\n",
    "B_arr_val_ends = np.cumsum(B_arr_val) - 1\n",
    "B_arr_test_starts = np.cumsum(B_arr_test) - B_arr_test\n",
    "B_arr_test_ends = np.cumsum(B_arr_test) - 1\n",
    "\n",
    "# sample train, assess and test data according to the B_arr's\n",
    "X_train, X_val, X_test = sample_X(X=X, B_arr = B_arr, B_arr_train=B_arr_train, B_arr_assess=B_arr_val)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary storing excess risk\n",
    "window_sizes_train = [1, 4, 16, 64, 256]\n",
    "window_sizes_val = [1, 4, 16, 64, 256]\n",
    "\n",
    "num_seeds = 20\n",
    "seeds = np.arange(num_seeds) + 2024\n",
    "\n",
    "excess_dict = {}\n",
    "excess_dict['ARW'] = {}\n",
    "for k in window_sizes_val:\n",
    "    excess_dict[f'Val_{k}'] = {}\n",
    "    for trial in range(len(seeds)):\n",
    "        excess_dict[f'Val_{k}'][trial] = []\n",
    "        excess_dict['ARW'][trial] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "M = 0\n",
    "test_means = []\n",
    "\n",
    "# for each period, train and select the best model\n",
    "for trial, seed in tqdm(enumerate(seeds)):\n",
    "    print('Trial:', trial)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # resample train, assess and test data according to the B_arr's\n",
    "    X_train, X_val, X_test = sample_X(X=X, B_arr = B_arr, B_arr_train=B_arr_train, B_arr_assess=B_arr_val)\n",
    "\n",
    "    # record the test means\n",
    "    test_means = []\n",
    "\n",
    "    for t in range(num_periods):\n",
    "\n",
    "        # get the t-th period test data\n",
    "        X_test_t = X_test[B_arr_test_starts[t]:B_arr_test_ends[t]+1]\n",
    "\n",
    "        # compute the mean of the t-th period test data\n",
    "        test_mean = np.mean(X_test_t)\n",
    "        test_means.append(test_mean)\n",
    "\n",
    "        # get the first t periods of training and validation data\n",
    "        X_train_t = X_train[:B_arr_train_ends[t]+1]\n",
    "        B_arr_train_t = B_arr_train[:t+1]\n",
    "        X_val_t = X_val[:B_arr_val_ends[t]+1]\n",
    "        B_arr_val_t = B_arr_val[:t+1]\n",
    "\n",
    "        #train fixed-window models\n",
    "        models = train_synthetic(X_train_t, B_arr_train_t, window_sizes_train)\n",
    "\n",
    "        #model selection using fixed-window validation data\n",
    "        indices_selected, models_selected = select_synthetic_fixed(X_val_t, B_arr_val_t, models, window_sizes_val)\n",
    "\n",
    "        for (i, k) in enumerate(window_sizes_val):\n",
    "            mu_hat_fixed_i = models_selected[i]\n",
    "            excess_risk = (test_mean - mu_hat_fixed_i) ** 2\n",
    "            excess_dict[f'Val_{k}'][trial].append(excess_risk)\n",
    "    \n",
    "        # model selection using rolling window\n",
    "        seed = 2024\n",
    "        idx_ARW, mu_hat_ARW = select_synthetic_ARW(X_val_t, B_arr_val_t, models, delta, M, seed)\n",
    "        excess_risk = (test_mean - mu_hat_ARW) ** 2\n",
    "        excess_dict['ARW'][trial].append(excess_risk)\n",
    "\n",
    "    # plot test means\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (5,5))\n",
    "    plt.plot(test_means)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Estimated Mean')\n",
    "    plt.tight_layout()\n",
    "    # change figure name accordingly\n",
    "    plt.savefig(f'./figures/test_means_{trial}.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0   # start time for plotting\n",
    "\n",
    "methods = list(excess_dict.keys())\n",
    "excess_array = np.zeros((len(methods), len(seeds), num_periods))\n",
    "\n",
    "for (i, method) in enumerate(excess_dict.keys()):\n",
    "    for (j, trial) in enumerate(excess_dict[method].keys()):\n",
    "        excess_array[i, j, :] = excess_dict[method][trial]\n",
    "\n",
    "# take average of excess risks over time and trials\n",
    "mean_excess_over_time_and_trial = np.mean(np.mean(excess_array[:, :, start_time:], axis=2), axis=1)\n",
    "mean_std_mse_over_time_and_trial = np.mean(np.std(excess_array[:, :, start_time:], axis=2), axis=1)\n",
    "\n",
    "# bar plot\n",
    "fig, ax = plt.subplots(1, 1, figsize = (5, 5))\n",
    "methods = list(excess_dict.keys())\n",
    "colors = ['tab:red', '#FFA500', 'tab:purple', 'tab:brown', 'tab:green', '#0096FF']\n",
    "for pos, method in enumerate(methods):\n",
    "    # bar plot the mean excess risk\n",
    "    plt.bar(pos, mean_excess_over_time_and_trial[pos], color=colors[pos])\n",
    "    print(method, mean_excess_over_time_and_trial[pos])\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "plt.xticks(np.arange(6), ['ARW', 'V1', 'V4', 'V16', 'V64', 'V256'])\n",
    "plt.xlabel('Model Selection Algorithms')\n",
    "plt.ylabel('Mean Excess Risk')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./figures/bar.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# line plot with 3 algorithms\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 2.5))\n",
    "plt.plot(excess_dict['ARW'][0][start_time:], color='r')\n",
    "plt.plot(excess_dict['Val_1'][0][start_time:], color='#FFA500')\n",
    "plt.plot(excess_dict['Val_256'][0][start_time:], color='#0096FF')\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Excess Risk')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./figures/line_few.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# line plot with many algorithms\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 2.5))\n",
    "plt.plot(excess_dict['ARW'][0][start_time:], color='r')\n",
    "plt.plot(excess_dict['Val_1'][0][start_time:], color='#FFA500')\n",
    "plt.plot(excess_dict['Val_4'][0][start_time:], color='purple')\n",
    "plt.plot(excess_dict['Val_16'][0][start_time:], color='brown')\n",
    "plt.plot(excess_dict['Val_64'][0][start_time:], color='green')\n",
    "plt.plot(excess_dict['Val_256'][0][start_time:], color='#0096FF')\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Excess Risk')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./figures/line_many.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_excess_over_time_and_trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
